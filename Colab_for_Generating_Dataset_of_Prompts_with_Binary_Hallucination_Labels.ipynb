{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "hnvcDMWIJcQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvVY2GT9JCO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1eecc6-2c67-4809-8b2c-3459d4b657d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4507\n",
            "Index(['input', 'label'], dtype='object')\n",
            "                                               input  label\n",
            "0  Produce a list of common words in the English ...      0\n",
            "1              Provide a few examples of homophones.      1\n",
            "2  Create a chart outlining the world's populatio...      1\n",
            "3         Design a shape with 10 vertices (corners).      1\n",
            "4  Automatically generate a 10 by 10 multiplicati...      1\n"
          ]
        }
      ],
      "source": [
        "# dataset from https://github.com/RUCAIBox/HaluEval\n",
        "df1 = pd.read_json(\"/content/general_data.json\", lines=True)\n",
        "\n",
        "# data cleaning, only need prompt and binary yes/no for hallucination\n",
        "df1.drop(['chatgpt_response', 'ID', 'hallucination_spans'], axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "df1['hallucination_binary'] = df1['hallucination'].map({'yes': 1, 'no': 0})\n",
        "\n",
        "df1.drop('hallucination', axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "# necessary for trainer\n",
        "df1.rename(columns={'hallucination_binary':'label'}, inplace=True)\n",
        "\n",
        "# rename for consistency\n",
        "df1.rename(columns={'user_query':'input'}, inplace=True)\n",
        "\n",
        "print(len(df1))\n",
        "print(df1.columns)\n",
        "print(df1.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# datasets from https://github.com/Arize-ai/LibreEval\n",
        "csv_file_paths = [\n",
        "    '/content/docs_databricks_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.txt',\n",
        "    '/content/earthobservatory_nasa_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.txt',\n",
        "    '/content/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.txt',\n",
        "    '/content/medlineplus_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.txt',\n",
        "    '/content/pmc_ncbi_nlm_nih_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.txt',\n",
        "    '/content/www_investopedia_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.txt',\n",
        "    '/content/www_law_cornell_edu_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.txt',\n",
        "    '/content/www_mongodb_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.txt',\n",
        "    '/content/www_ncbi_nlm_nih_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.txt',\n",
        "    '/content/www_noaa_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.txt',\n",
        "    ]\n",
        "df2_list = [pd.read_csv(file) for file in csv_file_paths]\n",
        "df2 = pd.concat(df2_list, ignore_index=True)\n",
        "\n",
        "df2.drop(columns=[\"reference\", \"output\", \"explanation_gpt-4o\",\n",
        "                  \"label_claude-3-5-sonnet-latest\", \"explanation_claude-3-5-sonnet-latest\",\n",
        "                  \"label_litellm/together_ai/Qwen/Qwen2.5-7B-Instruct-Turbo\",\n",
        "                  \"explanation_litellm/together_ai/Qwen/Qwen2.5-7B-Instruct-Turbo\",\n",
        "                  \"rag_model\", \"force_even_split\", \"website\", \"synthetic\",\n",
        "                  \"language\", \"hallucination_type_realized\", \"question_type\", \"hallucination_type_encouraged\",\n",
        "                  \"hallucination_type_realized_ensemble\", \"label_mistral-large-latest\",\n",
        "                  \"explanation_mistral-large-latest\", \"human_label\", \"label_gpt-4o\"], errors=\"ignore\", inplace=True)\n",
        "\n",
        "df2 = df2[df2['label'].str.upper() != \"NOT_PARSABLE\"]\n",
        "df2['label'] = df2['label'].map({'hallucinated': 1, 'factual': 0})\n",
        "\n",
        "print(len(df2))\n",
        "print(df2.columns)\n",
        "print(df2.head())"
      ],
      "metadata": {
        "id": "FzI7NyluJbKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eae83f6-b595-4ab2-d2ef-056753471e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4246\n",
            "Index(['input', 'label'], dtype='object')\n",
            "                                               input  label\n",
            "0  What actions can be performed on an external l...      0\n",
            "1  What versions of Databricks Runtime does the i...      0\n",
            "2  What is the default access restriction for mat...      0\n",
            "3  Who can query materialized views and streaming...      0\n",
            "4  What is required to enable Iceberg reads on ta...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset from https://huggingface.co/datasets/opencompass/anah?row=0\n",
        "from datasets import load_dataset\n",
        "\n",
        "anah_dataset = load_dataset(\"opencompass/anah\")\n",
        "\n",
        "# only has train set on hugging face\n",
        "df3 = anah_dataset[\"train\"].to_pandas()\n",
        "\n",
        "# drop non-gpt columns\n",
        "df3.drop(columns=[\"InternLM_answers\", \"human_InternLM_answers_ann\", \"name\", \"documents\", \"language\", \"GPT3.5_answers_D\"], inplace=True)\n",
        "\n",
        "# get true/false hallucination data, code from ChatGPT\n",
        "df3['label'] = df3['human_GPT3.5_answers_D_ann'].apply(\n",
        "    lambda ann: any('<Hallucination>' in str(a) for a in ann)\n",
        ")\n",
        "\n",
        "df3['label'] = df3['label'].map({True: 1, False: 0})\n",
        "\n",
        "# remove LLM response\n",
        "df3.drop(columns=\"human_GPT3.5_answers_D_ann\", inplace=True)\n",
        "\n",
        "# rename for consistency\n",
        "df3.rename(columns={'selected_questions':'input'}, inplace=True)\n",
        "\n",
        "# extract strings for arrays in every row, code from ChatGPT\n",
        "\n",
        "df3['input'] = df3['input'].apply(\n",
        "    lambda x: x[0] if isinstance(x, (list, np.ndarray)) and len(x) > 0 else x\n",
        ")\n",
        "\n",
        "print(df3.head())\n",
        "print(df3.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouiiV-sALRr3",
        "outputId": "648226ce-8dd2-4f00-c05a-596614e77fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               input  label\n",
            "0  What was the aftermath of the Battle of Sobrao...      1\n",
            "1  What were the consequences of the Kapp Putsch ...      1\n",
            "2  What were the main factors leading to the Batt...      0\n",
            "3  How did the Battle of the Camel unfold, and wh...      0\n",
            "4  How was the leadership vote conducted and what...      1\n",
            "Index(['input', 'label'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "print(combined_df.shape)\n",
        "print(combined_df.columns)\n",
        "print(combined_df.head())\n",
        "\n",
        "print(df2['label'].value_counts())\n",
        "\n",
        "\n",
        "combined_df.to_csv(\"final_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "cJBe95NFJSXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8d1448-902c-47b5-a841-130f26997080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9536, 2)\n",
            "Index(['input', 'label'], dtype='object')\n",
            "                                               input  label\n",
            "0  Produce a list of common words in the English ...      0\n",
            "1              Provide a few examples of homophones.      1\n",
            "2  Create a chart outlining the world's populatio...      1\n",
            "3         Design a shape with 10 vertices (corners).      1\n",
            "4  Automatically generate a 10 by 10 multiplicati...      1\n",
            "label\n",
            "0    7291\n",
            "1    2245\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}